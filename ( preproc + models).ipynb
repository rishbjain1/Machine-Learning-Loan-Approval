{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6302a26",
   "metadata": {
    "id": "f6302a26",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-and-Load-Data\" data-toc-modified-id=\"Import-and-Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import and Load Data</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Trying-Out-Models\" data-toc-modified-id=\"Trying-Out-Models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Trying Out Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Support Vector Machine</a></span></li><li><span><a href=\"#Decision-Trees-(Random-Forest,-Gradient-Boosting,-XGBoost)\" data-toc-modified-id=\"Decision-Trees-(Random-Forest,-Gradient-Boosting,-XGBoost)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Decision Trees (Random Forest, Gradient Boosting, XGBoost)</a></span></li><li><span><a href=\"#Other-Models-(e.g.-Bagging-Classifier)\" data-toc-modified-id=\"Other-Models-(e.g.-Bagging-Classifier)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Other Models (e.g. Bagging Classifier)</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a31f2b",
   "metadata": {
    "id": "b9a31f2b"
   },
   "source": [
    "## Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9725cdaa",
   "metadata": {
    "id": "9725cdaa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da6fb46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9da6fb46",
    "outputId": "b43a9aeb-82c4-4de7-ce7f-ba02101c5a9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/_8lh9zpx0vbc_x2bq621qrhc0000gn/T/ipykernel_90154/2297142626.py:18: DtypeWarning: Columns (20,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('loans.csv')\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#from google.colab import drive\n",
    "#import zipfile\n",
    "\n",
    "# Mount Google Drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Extract the ZIP file containing the CSV\n",
    "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/OMIS116 (1)/loans.csv.zip\", 'r')\n",
    "#zip_ref.extractall(\"/content/dataset\")\n",
    "#zip_ref.close()\n",
    "\n",
    "# Assuming the CSV file is named loans.csv and is directly inside the zip without any folder structure\n",
    "#csv_file_path = \"/content/dataset/loans.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "#df = pd.read_csv(csv_file_path)\n",
    "df = pd.read_csv('loans.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e6bb3",
   "metadata": {
    "id": "481e6bb3"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    " - Handle missing values\n",
    " - Encode categorical variables, scale data (if you wish), feature selection, etc.\n",
    " - Split the dataset into features (X) and target variable (y)\n",
    " - Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a10542-79f3-4b92-8d3c-e1bcb08c2131",
   "metadata": {
    "id": "84a10542-79f3-4b92-8d3c-e1bcb08c2131"
   },
   "outputs": [],
   "source": [
    "df.drop(['id','member_id','emp_title','title','zip_code','url'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f7137e-8194-4b07-b420-01d963f5675e",
   "metadata": {
    "id": "93f7137e-8194-4b07-b420-01d963f5675e"
   },
   "outputs": [],
   "source": [
    "df['emp_length'] = df['emp_length'].str.extract('(\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d661f86a-3f09-4e6b-8b13-384c34c69f59",
   "metadata": {
    "id": "d661f86a-3f09-4e6b-8b13-384c34c69f59"
   },
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69aa64f5-1cc3-47af-8dc6-815c335604e2",
   "metadata": {
    "id": "69aa64f5-1cc3-47af-8dc6-815c335604e2"
   },
   "outputs": [],
   "source": [
    "threshold = len(df) * 0.10 # 90% threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe29c56c-27d7-4d06-a1da-5f6201bf9109",
   "metadata": {
    "id": "fe29c56c-27d7-4d06-a1da-5f6201bf9109"
   },
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(axis = 1, thresh = threshold) # dropped columns that have more than 80% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb53c5eb",
   "metadata": {
    "id": "cb53c5eb"
   },
   "outputs": [],
   "source": [
    "continuous_columns = ['loan_amnt', 'installment', 'funded_amnt','funded_amnt_inv', 'annual_inc', 'dti', \\\n",
    "                      'revol_bal', 'revol_util', 'total_rev_hi_lim','total_acc',\\\n",
    "                      'int_rate', 'pub_rec', 'delinq_2yrs','inq_last_6mths','open_acc','acc_now_delinq', 'emp_length'\n",
    "                     ]\n",
    "nominal_columns = ['home_ownership', 'pymnt_plan', 'term', 'application_type', 'initial_list_status', 'purpose',  'verification_status',\\\n",
    "                    'sub_grade', 'addr_state']\n",
    "ordinal_columns = []\n",
    "time_columns = ['earliest_cr_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e731e89",
   "metadata": {
    "id": "9e731e89"
   },
   "outputs": [],
   "source": [
    "total_cols = nominal_columns + continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ceb8bd9-4e60-4916-8b2d-eba2d6958922",
   "metadata": {
    "id": "6ceb8bd9-4e60-4916-8b2d-eba2d6958922"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('nominal', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "        ]), nominal_columns),\n",
    "        ('continuous', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), continuous_columns),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e9ea94-20d7-48dd-9512-3c93f63cbe4f",
   "metadata": {
    "id": "b1e9ea94-20d7-48dd-9512-3c93f63cbe4f"
   },
   "outputs": [],
   "source": [
    "desired_statuses = ['Fully Paid', 'Default', 'Charged Off']\n",
    "\n",
    "df_cleaned = df[df['loan_status'].isin(desired_statuses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1286edd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1286edd7",
    "outputId": "f9c698c8-6cd3-4f40-ee03-3348d9bc7934"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/_8lh9zpx0vbc_x2bq621qrhc0000gn/T/ipykernel_90154/2618706337.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['binary_loan_status'] = df_cleaned['loan_status'].apply(lambda x: 1 if x in ['Fully Paid'] else 0)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['binary_loan_status'] = df_cleaned['loan_status'].apply(lambda x: 1 if x in ['Fully Paid'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc6a135-d7ea-47e8-91f4-1d6ad0cc80d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efc6a135-d7ea-47e8-91f4-1d6ad0cc80d9",
    "outputId": "9c147507-e82b-449d-b5d9-9777d93b983b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/_8lh9zpx0vbc_x2bq621qrhc0000gn/T/ipykernel_90154/3704106794.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.drop(columns = 'loan_status', inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.drop(columns = 'loan_status', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c97118-285f-4b39-80dc-2448bcf7d734",
   "metadata": {
    "id": "28c97118-285f-4b39-80dc-2448bcf7d734"
   },
   "outputs": [],
   "source": [
    "X = df_cleaned[total_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e08703bb",
   "metadata": {
    "id": "e08703bb"
   },
   "outputs": [],
   "source": [
    "y = df_cleaned.binary_loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16fb37fe",
   "metadata": {
    "id": "16fb37fe"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, shuffle = True, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170129a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d0170",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a72613b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "a72613b8",
    "outputId": "7f4ee1b9-a176-4291-f6fd-1a184d1c11d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:  0.7047060488150438\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#advanced logistic regression code\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "# Parameters of the logistic regression to be tuned through cross-validation\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100,1000, 10000],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Custom scorer for optimizing the hyperparameters based on AUC\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=auc_scorer, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = grid_search.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute AUC score\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40a0ce",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30b6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff407d21",
   "metadata": {},
   "source": [
    "### Decision Trees (Random Forest, Gradient Boosting, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree simnple\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth = 5)\n",
    "\n",
    "# Setup the pipeline for preprocessing and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', dt_classifier)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree advanced\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Setup the pipeline for preprocessing and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', dt_classifier)])\n",
    "\n",
    "# Parameters to search for the Decision Tree Classifier\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 10, 50],\n",
    "    'classifier__min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "# Setup GridSearchCV to find the best parameters using cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = grid_search.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier sample\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Setup the pipeline for preprocessing and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', rf_classifier)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Setup the pipeline for preprocessing and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', rf_classifier)])\n",
    "\n",
    "# Parameters to search for the Random Forest Classifier\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'classifier__max_depth': [10, 20, 30],  # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 10, 50],  # Minimum number of samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 5, 10]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV to find the best parameters using cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', verbose=1)\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f160ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting simple\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the pipeline steps\n",
    "pipeline_steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42, n_iter_no_change=10))]\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the pipeline steps\n",
    "pipeline_steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42, n_iter_no_change=10))\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=pipeline_steps)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best AUC score found: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_prob = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUC score on the test set\n",
    "test_auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC score on the test set: \", test_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost simple\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a pipeline that includes the preprocessing steps and the classifier\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a pipeline that includes the preprocessing steps and the classifier\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter space for the XGBoost model\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [3, 6],\n",
    "    'classifier__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best AUC found: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_proba = grid_search.predict_proba(X_test)[:,1]\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score on Test Set: \", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708da332",
   "metadata": {},
   "source": [
    "### Other Models (e.g. Bagging Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging simple\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "bag_clf = BaggingClassifier(dtree,\n",
    "                           n_estimators = 500,\n",
    "                           max_samples = 100,\n",
    "                           n_jobs = -1, random_state = 42)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', bag_clf)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e08a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the base estimator\n",
    "base_estimator = DecisionTreeClassifier(random_state=42, max_depth = 5)\n",
    "\n",
    "# Initialize the BaggingClassifier with the Decision Tree as the base estimator\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Create a pipeline with preprocessing and the classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', bagging_clf)])\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'max_samples':[0.5,0.75,1.0],\n",
    "    'max_features':[0.5,0.75,1.0],\n",
    "    'bootstrap':[True, False]\n",
    "    'bootstrap_features':[False, True]\n",
    "    # Example: trying 10, 50, and 100 trees in the ensemble\n",
    "    # Add other parameters here if you wish to tune them\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV to find the best parameters for both the model and preprocessing\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameter set found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae559e",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Compare the best models' performance on the test data. Which one does the best? Which one the worst? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8775172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
